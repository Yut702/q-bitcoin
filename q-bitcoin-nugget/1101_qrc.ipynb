{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc2b063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import AerSimulator\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76da0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumReservoirComputing:\n",
    "    def __init__(self, n_qubits=4, depth=3, alpha=1.0):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.depth = depth\n",
    "        self.alpha = alpha\n",
    "        self.simulator = AerSimulator()\n",
    "        self.readout_model = Ridge(alpha=alpha)\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "        # リザバー回路を事前に構築(固定)\n",
    "        self.reservoir_circuit = self._build_reservoir()\n",
    "\n",
    "    def _build_reservoir(self):\n",
    "        \"\"\"固定されたリザバー回路を構築\"\"\"\n",
    "        qc = QuantumCircuit(self.n_qubits)\n",
    "        np.random.seed(42)  # 再現性\n",
    "\n",
    "        for d in range(self.depth):\n",
    "            # ランダムな単一量子ビット回転\n",
    "            for i in range(self.n_qubits):\n",
    "                qc.rx(np.random.uniform(0, 2*np.pi), i)\n",
    "                qc.ry(np.random.uniform(0, 2*np.pi), i)\n",
    "                qc.rz(np.random.uniform(0, 2*np.pi), i)\n",
    "\n",
    "            # エンタングルメント\n",
    "            for i in range(self.n_qubits-1):\n",
    "                qc.cx(i, i+1)\n",
    "            qc.cx(self.n_qubits-1, 0)\n",
    "\n",
    "        return qc\n",
    "\n",
    "    def _encode_input(self, qc, x):\n",
    "        \"\"\"入力データを量子状態にエンコード\"\"\"\n",
    "        for i in range(min(len(x), self.n_qubits)):\n",
    "            qc.ry(x[i] * np.pi, i)\n",
    "        return qc\n",
    "\n",
    "    def _extract_features(self, qc, shots=1000):\n",
    "        \"\"\"量子回路を測定して特徴を抽出\"\"\"\n",
    "        qc_copy = qc.copy()\n",
    "        qc_copy.measure_all()\n",
    "\n",
    "        job = self.simulator.run(qc_copy, shots=shots)\n",
    "        counts = job.result().get_counts()\n",
    "\n",
    "        # 確率分布を特徴ベクトルに変換\n",
    "        n_states = 2**self.n_qubits\n",
    "        features = np.zeros(n_states)\n",
    "\n",
    "        for bitstring, count in counts.items():\n",
    "            idx = int(bitstring, 2)\n",
    "            features[idx] = count / shots\n",
    "\n",
    "        return features\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        データセットを量子特徴に変換\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        quantum_features : array, shape (n_samples, 2^n_qubits)\n",
    "        \"\"\"\n",
    "        quantum_features = []\n",
    "        \n",
    "        print(f\"Processing {len(X)} samples...\")\n",
    "        for i, x in enumerate(X):\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(f\"  {i+1}/{len(X)} samples processed\")\n",
    "            \n",
    "            # 新しい回路を作成\n",
    "            qc = QuantumCircuit(self.n_qubits)\n",
    "            \n",
    "            # 入力をエンコード\n",
    "            qc = self._encode_input(qc, x)\n",
    "            \n",
    "            # リザバー回路を適用\n",
    "            qc = qc.compose(self.reservoir_circuit)\n",
    "            \n",
    "            # 特徴を抽出\n",
    "            features = self._extract_features(qc)\n",
    "            quantum_features.append(features)\n",
    "        \n",
    "        return np.array(quantum_features)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        量子特徴を抽出して出力層を学習\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "        y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
    "        \"\"\"\n",
    "        # データを正規化\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # 量子特徴に変換\n",
    "        quantum_features = self.transform(X_scaled)\n",
    "        \n",
    "        # 出力層を学習\n",
    "        self.readout_model.fit(quantum_features, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        予測を実行\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        predictions : array, shape (n_samples,) or (n_samples, n_outputs)\n",
    "        \"\"\"\n",
    "        # データを正規化\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # 量子特徴に変換\n",
    "        quantum_features = self.transform(X_scaled)\n",
    "        \n",
    "        # 予測\n",
    "        predictions = self.readout_model.predict(quantum_features)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "640706b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series plot saved to 'comparison_timeseries.png'\n",
      "Scatter plot saved to 'comparison_scatter.png'\n",
      "Error distribution plot saved to 'comparison_error_dist.png'\n",
      "Metrics comparison plot saved to 'comparison_metrics.png'\n",
      "Metrics table saved to 'comparison_table.png'\n",
      "\n",
      "======================================================================\n",
      "PREDICTION COMPARISON SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Tenor_10_Mat_30:\n",
      "----------------------------------------------------------------------\n",
      "Model                         MSE          MAE           R²         RMSE\n",
      "----------------------------------------------------------------------\n",
      "Linear Regression        3.656363     1.538679       0.9457     1.912162\n",
      "QRC                      7.298574     2.129872       0.8916     2.701587\n",
      "Random Forest            2.388992     1.241258       0.9645     1.545637\n",
      "\n",
      "Tenor_15_Mat_30:\n",
      "----------------------------------------------------------------------\n",
      "Model                         MSE          MAE           R²         RMSE\n",
      "----------------------------------------------------------------------\n",
      "Linear Regression        4.261231     1.677639       0.9551     2.064275\n",
      "QRC                      8.818482     2.409524       0.9071     2.969593\n",
      "Random Forest            2.170925     1.194639       0.9771     1.473406\n",
      "\n",
      "Tenor_20_Mat_30:\n",
      "----------------------------------------------------------------------\n",
      "Model                         MSE          MAE           R²         RMSE\n",
      "----------------------------------------------------------------------\n",
      "Linear Regression        3.147466     1.387620       0.9743     1.774110\n",
      "QRC                     10.796777     2.658348       0.9119     3.285845\n",
      "Random Forest            2.365594     1.186403       0.9807     1.538049\n",
      "\n",
      "======================================================================\n",
      "AVERAGE ACROSS ALL FEATURES:\n",
      "----------------------------------------------------------------------\n",
      "Model                         MSE          MAE           R²         RMSE\n",
      "----------------------------------------------------------------------\n",
      "Linear Regression        3.688353     1.534646       0.9584     1.920509\n",
      "QRC                      8.971278     2.399248       0.9036     2.995209\n",
      "Random Forest            2.308504     1.207433       0.9741     1.519376\n",
      "======================================================================\n",
      "Detailed comparison plot saved to 'detailed_comparison.png'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_comprehensive_comparison(y_test, y_pred_dict, feature_names=None, save_path='prediction_comparison.png'):\n",
    "    \"\"\"\n",
    "    予測値と理論値を包括的に比較するプロット\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_test : array, shape (n_samples,) or (n_samples, n_features)\n",
    "        真の値\n",
    "    y_pred_dict : dict\n",
    "        {'model_name': y_pred} の形式\n",
    "        例: {'Linear Regression': y_pred_lr, 'QRC': y_pred_qrc}\n",
    "    feature_names : list, optional\n",
    "        各特徴量(列)の名前\n",
    "    save_path : str\n",
    "        保存先のパス\n",
    "    \"\"\"\n",
    "    \n",
    "    # データの形状を確認\n",
    "    if y_test.ndim == 1:\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "    \n",
    "    n_samples, n_features = y_test.shape\n",
    "    n_models = len(y_pred_dict)\n",
    "    \n",
    "    # 特徴量名の設定\n",
    "    if feature_names is None:\n",
    "        feature_names = [f'Feature {i}' for i in range(n_features)]\n",
    "    \n",
    "    # 各モデルの予測値も2次元に\n",
    "    for model_name in y_pred_dict:\n",
    "        if y_pred_dict[model_name].ndim == 1:\n",
    "            y_pred_dict[model_name] = y_pred_dict[model_name].reshape(-1, 1)\n",
    "    \n",
    "    # ===== プロット1: 時系列プロット =====\n",
    "    n_cols = min(3, n_features)\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig1, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 4*n_rows))\n",
    "    if n_features == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, n_models + 1))\n",
    "    \n",
    "    for feat_idx in range(n_features):\n",
    "        ax = axes[feat_idx]\n",
    "        \n",
    "        # 真の値\n",
    "        ax.plot(y_test[:, feat_idx], \n",
    "                label='True Value', \n",
    "                color=colors[0], \n",
    "                linewidth=2, \n",
    "                marker='o', \n",
    "                markersize=4,\n",
    "                alpha=0.7)\n",
    "        \n",
    "        # 各モデルの予測\n",
    "        for model_idx, (model_name, y_pred) in enumerate(y_pred_dict.items()):\n",
    "            ax.plot(y_pred[:, feat_idx], \n",
    "                    label=model_name, \n",
    "                    color=colors[model_idx + 1],\n",
    "                    linewidth=1.5,\n",
    "                    marker='x',\n",
    "                    markersize=4,\n",
    "                    alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Time Step', fontsize=10)\n",
    "        ax.set_ylabel('Value', fontsize=10)\n",
    "        ax.set_title(f'{feature_names[feat_idx]}', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 空のサブプロットを非表示\n",
    "    for idx in range(n_features, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path.replace('.png', '_timeseries.png'), dpi=300, bbox_inches='tight')\n",
    "    print(f\"Time series plot saved to '{save_path.replace('.png', '_timeseries.png')}'\")\n",
    "    \n",
    "    # ===== プロット2: 散布図(True vs Predicted) =====\n",
    "    fig2, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 4*n_rows))\n",
    "    if n_features == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for feat_idx in range(n_features):\n",
    "        ax = axes[feat_idx]\n",
    "        \n",
    "        # 各モデルの散布図\n",
    "        for model_idx, (model_name, y_pred) in enumerate(y_pred_dict.items()):\n",
    "            ax.scatter(y_test[:, feat_idx], \n",
    "                      y_pred[:, feat_idx], \n",
    "                      label=model_name,\n",
    "                      color=colors[model_idx + 1],\n",
    "                      alpha=0.6,\n",
    "                      s=50,\n",
    "                      edgecolors='black',\n",
    "                      linewidth=0.5)\n",
    "        \n",
    "        # 理想的な予測線(y=x)\n",
    "        min_val = min(y_test[:, feat_idx].min(), \n",
    "                     min([y_pred[:, feat_idx].min() for y_pred in y_pred_dict.values()]))\n",
    "        max_val = max(y_test[:, feat_idx].max(),\n",
    "                     max([y_pred[:, feat_idx].max() for y_pred in y_pred_dict.values()]))\n",
    "        \n",
    "        ax.plot([min_val, max_val], [min_val, max_val], \n",
    "                'r--', linewidth=2, label='Ideal', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('True Value', fontsize=10)\n",
    "        ax.set_ylabel('Predicted Value', fontsize=10)\n",
    "        ax.set_title(f'{feature_names[feat_idx]}', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    # 空のサブプロットを非表示\n",
    "    for idx in range(n_features, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path.replace('.png', '_scatter.png'), dpi=300, bbox_inches='tight')\n",
    "    print(f\"Scatter plot saved to '{save_path.replace('.png', '_scatter.png')}'\")\n",
    "    \n",
    "    # ===== プロット3: 誤差分布 =====\n",
    "    fig3, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 4*n_rows))\n",
    "    if n_features == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for feat_idx in range(n_features):\n",
    "        ax = axes[feat_idx]\n",
    "        \n",
    "        # 各モデルの誤差のヒストグラム\n",
    "        for model_idx, (model_name, y_pred) in enumerate(y_pred_dict.items()):\n",
    "            errors = y_test[:, feat_idx] - y_pred[:, feat_idx]\n",
    "            ax.hist(errors, \n",
    "                   bins=20, \n",
    "                   alpha=0.6, \n",
    "                   label=f'{model_name}\\n(μ={errors.mean():.4f}, σ={errors.std():.4f})',\n",
    "                   color=colors[model_idx + 1],\n",
    "                   edgecolor='black')\n",
    "        \n",
    "        ax.axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero Error')\n",
    "        ax.set_xlabel('Error (True - Predicted)', fontsize=10)\n",
    "        ax.set_ylabel('Frequency', fontsize=10)\n",
    "        ax.set_title(f'{feature_names[feat_idx]}', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=7)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 空のサブプロットを非表示\n",
    "    for idx in range(n_features, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path.replace('.png', '_error_dist.png'), dpi=300, bbox_inches='tight')\n",
    "    print(f\"Error distribution plot saved to '{save_path.replace('.png', '_error_dist.png')}'\")\n",
    "    \n",
    "    # ===== プロット4: メトリクス比較 =====\n",
    "    fig4, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    metrics_data = {\n",
    "        'MSE': [],\n",
    "        'MAE': [],\n",
    "        'R²': []\n",
    "    }\n",
    "    \n",
    "    model_names_list = list(y_pred_dict.keys())\n",
    "    \n",
    "    # 各特徴量の平均メトリクスを計算\n",
    "    for model_name, y_pred in y_pred_dict.items():\n",
    "        mse_list = []\n",
    "        mae_list = []\n",
    "        r2_list = []\n",
    "        \n",
    "        for feat_idx in range(n_features):\n",
    "            mse = mean_squared_error(y_test[:, feat_idx], y_pred[:, feat_idx])\n",
    "            mae = mean_absolute_error(y_test[:, feat_idx], y_pred[:, feat_idx])\n",
    "            r2 = r2_score(y_test[:, feat_idx], y_pred[:, feat_idx])\n",
    "            \n",
    "            mse_list.append(mse)\n",
    "            mae_list.append(mae)\n",
    "            r2_list.append(r2)\n",
    "        \n",
    "        metrics_data['MSE'].append(np.mean(mse_list))\n",
    "        metrics_data['MAE'].append(np.mean(mae_list))\n",
    "        metrics_data['R²'].append(np.mean(r2_list))\n",
    "    \n",
    "    # MSE\n",
    "    axes[0].bar(model_names_list, metrics_data['MSE'], color=colors[1:n_models+1], alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_ylabel('MSE', fontsize=12)\n",
    "    axes[0].set_title('Mean Squared Error', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # MAE\n",
    "    axes[1].bar(model_names_list, metrics_data['MAE'], color=colors[1:n_models+1], alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_ylabel('MAE', fontsize=12)\n",
    "    axes[1].set_title('Mean Absolute Error', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # R²\n",
    "    axes[2].bar(model_names_list, metrics_data['R²'], color=colors[1:n_models+1], alpha=0.7, edgecolor='black')\n",
    "    axes[2].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "    axes[2].set_ylabel('R²', fontsize=12)\n",
    "    axes[2].set_title('R² Score', fontsize=14, fontweight='bold')\n",
    "    axes[2].grid(True, alpha=0.3, axis='y')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path.replace('.png', '_metrics.png'), dpi=300, bbox_inches='tight')\n",
    "    print(f\"Metrics comparison plot saved to '{save_path.replace('.png', '_metrics.png')}'\")\n",
    "    \n",
    "    # ===== プロット5: 詳細メトリクステーブル =====\n",
    "    fig5, ax = plt.subplots(figsize=(12, max(6, n_features * 0.8)))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # テーブルデータの作成\n",
    "    table_data = []\n",
    "    headers = ['Feature', 'Model', 'MSE', 'MAE', 'R²', 'RMSE']\n",
    "    \n",
    "    for feat_idx in range(n_features):\n",
    "        for model_name, y_pred in y_pred_dict.items():\n",
    "            mse = mean_squared_error(y_test[:, feat_idx], y_pred[:, feat_idx])\n",
    "            mae = mean_absolute_error(y_test[:, feat_idx], y_pred[:, feat_idx])\n",
    "            r2 = r2_score(y_test[:, feat_idx], y_pred[:, feat_idx])\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            table_data.append([\n",
    "                feature_names[feat_idx],\n",
    "                model_name,\n",
    "                f'{mse:.6f}',\n",
    "                f'{mae:.6f}',\n",
    "                f'{r2:.4f}',\n",
    "                f'{rmse:.6f}'\n",
    "            ])\n",
    "    \n",
    "    table = ax.table(cellText=table_data, \n",
    "                     colLabels=headers,\n",
    "                     cellLoc='center',\n",
    "                     loc='center',\n",
    "                     colWidths=[0.15, 0.2, 0.15, 0.15, 0.15, 0.15])\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # ヘッダーのスタイル\n",
    "    for i in range(len(headers)):\n",
    "        table[(0, i)].set_facecolor('#4CAF50')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    # 行の色分け\n",
    "    for i in range(1, len(table_data) + 1):\n",
    "        if i % 2 == 0:\n",
    "            for j in range(len(headers)):\n",
    "                table[(i, j)].set_facecolor('#f0f0f0')\n",
    "    \n",
    "    plt.title('Detailed Metrics Table', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.savefig(save_path.replace('.png', '_table.png'), dpi=300, bbox_inches='tight')\n",
    "    print(f\"Metrics table saved to '{save_path.replace('.png', '_table.png')}'\")\n",
    "    \n",
    "    plt.close('all')\n",
    "    \n",
    "    # ===== コンソール出力 =====\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PREDICTION COMPARISON SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for feat_idx in range(n_features):\n",
    "        print(f\"\\n{feature_names[feat_idx]}:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"{'Model':<20} {'MSE':>12} {'MAE':>12} {'R²':>12} {'RMSE':>12}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for model_name, y_pred in y_pred_dict.items():\n",
    "            mse = mean_squared_error(y_test[:, feat_idx], y_pred[:, feat_idx])\n",
    "            mae = mean_absolute_error(y_test[:, feat_idx], y_pred[:, feat_idx])\n",
    "            r2 = r2_score(y_test[:, feat_idx], y_pred[:, feat_idx])\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            print(f\"{model_name:<20} {mse:>12.6f} {mae:>12.6f} {r2:>12.4f} {rmse:>12.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"AVERAGE ACROSS ALL FEATURES:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Model':<20} {'MSE':>12} {'MAE':>12} {'R²':>12} {'RMSE':>12}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for model_name, y_pred in y_pred_dict.items():\n",
    "        mse_avg = np.mean([mean_squared_error(y_test[:, i], y_pred[:, i]) for i in range(n_features)])\n",
    "        mae_avg = np.mean([mean_absolute_error(y_test[:, i], y_pred[:, i]) for i in range(n_features)])\n",
    "        r2_avg = np.mean([r2_score(y_test[:, i], y_pred[:, i]) for i in range(n_features)])\n",
    "        rmse_avg = np.sqrt(mse_avg)\n",
    "        \n",
    "        print(f\"{model_name:<20} {mse_avg:>12.6f} {mae_avg:>12.6f} {r2_avg:>12.4f} {rmse_avg:>12.6f}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n",
    "def plot_single_feature_detailed(y_test, y_pred_dict, feature_idx=0, feature_name=None, save_path='detailed_comparison.png'):\n",
    "    \"\"\"\n",
    "    単一の特徴量に対する詳細な比較プロット\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_test : array, shape (n_samples,) or (n_samples, n_features)\n",
    "    y_pred_dict : dict\n",
    "    feature_idx : int\n",
    "        表示する特徴量のインデックス\n",
    "    feature_name : str, optional\n",
    "    save_path : str\n",
    "    \"\"\"\n",
    "    \n",
    "    if y_test.ndim == 1:\n",
    "        y_true = y_test\n",
    "    else:\n",
    "        y_true = y_test[:, feature_idx]\n",
    "    \n",
    "    if feature_name is None:\n",
    "        feature_name = f'Feature {feature_idx}'\n",
    "    \n",
    "    # 各モデルの予測値を抽出\n",
    "    predictions = {}\n",
    "    for model_name, y_pred in y_pred_dict.items():\n",
    "        if y_pred.ndim == 1:\n",
    "            predictions[model_name] = y_pred\n",
    "        else:\n",
    "            predictions[model_name] = y_pred[:, feature_idx]\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(predictions) + 1))\n",
    "    \n",
    "    # 1. 時系列プロット(大きめ)\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax1.plot(y_true, label='True Value', color=colors[0], linewidth=2.5, marker='o', markersize=5, alpha=0.8)\n",
    "    for idx, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "        ax1.plot(y_pred, label=model_name, color=colors[idx+1], linewidth=2, marker='x', markersize=5, alpha=0.7)\n",
    "    ax1.set_xlabel('Time Step', fontsize=12)\n",
    "    ax1.set_ylabel('Value', fontsize=12)\n",
    "    ax1.set_title(f'Time Series: {feature_name}', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(loc='best', fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 散布図\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    for idx, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "        ax2.scatter(y_true, y_pred, label=model_name, color=colors[idx+1], alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    min_val = min(y_true.min(), min([p.min() for p in predictions.values()]))\n",
    "    max_val = max(y_true.max(), max([p.max() for p in predictions.values()]))\n",
    "    ax2.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Ideal')\n",
    "    ax2.set_xlabel('True Value', fontsize=10)\n",
    "    ax2.set_ylabel('Predicted Value', fontsize=10)\n",
    "    ax2.set_title('Scatter Plot', fontsize=12, fontweight='bold')\n",
    "    ax2.legend(loc='best', fontsize=8)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    # 3. 誤差の時系列\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    for idx, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "        errors = y_true - y_pred\n",
    "        ax3.plot(errors, label=model_name, color=colors[idx+1], linewidth=1.5, alpha=0.7)\n",
    "    ax3.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "    ax3.set_xlabel('Time Step', fontsize=10)\n",
    "    ax3.set_ylabel('Error (True - Predicted)', fontsize=10)\n",
    "    ax3.set_title('Error Over Time', fontsize=12, fontweight='bold')\n",
    "    ax3.legend(loc='best', fontsize=8)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 誤差分布\n",
    "    ax4 = fig.add_subplot(gs[1, 2])\n",
    "    for idx, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "        errors = y_true - y_pred\n",
    "        ax4.hist(errors, bins=20, alpha=0.6, label=f'{model_name}\\nμ={errors.mean():.4f}\\nσ={errors.std():.4f}',\n",
    "                color=colors[idx+1], edgecolor='black')\n",
    "    ax4.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "    ax4.set_xlabel('Error', fontsize=10)\n",
    "    ax4.set_ylabel('Frequency', fontsize=10)\n",
    "    ax4.set_title('Error Distribution', fontsize=12, fontweight='bold')\n",
    "    ax4.legend(loc='best', fontsize=7)\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 5. 残差プロット\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    for idx, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "        residuals = y_true - y_pred\n",
    "        ax5.scatter(y_pred, residuals, label=model_name, color=colors[idx+1], alpha=0.6, s=50)\n",
    "    ax5.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "    ax5.set_xlabel('Predicted Value', fontsize=10)\n",
    "    ax5.set_ylabel('Residual', fontsize=10)\n",
    "    ax5.set_title('Residual Plot', fontsize=12, fontweight='bold')\n",
    "    ax5.legend(loc='best', fontsize=8)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. QQプロット\n",
    "    from scipy import stats\n",
    "    ax6 = fig.add_subplot(gs[2, 1])\n",
    "    for idx, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "        errors = y_true - y_pred\n",
    "        stats.probplot(errors, dist=\"norm\", plot=ax6)\n",
    "        ax6.get_lines()[idx*2].set_color(colors[idx+1])\n",
    "        ax6.get_lines()[idx*2].set_label(model_name)\n",
    "    ax6.set_title('Q-Q Plot', fontsize=12, fontweight='bold')\n",
    "    ax6.legend(loc='best', fontsize=8)\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. メトリクスバー\n",
    "    ax7 = fig.add_subplot(gs[2, 2])\n",
    "    metrics = {'MSE': [], 'MAE': [], 'R²': []}\n",
    "    model_names = list(predictions.keys())\n",
    "    \n",
    "    for model_name, y_pred in predictions.items():\n",
    "        metrics['MSE'].append(mean_squared_error(y_true, y_pred))\n",
    "        metrics['MAE'].append(mean_absolute_error(y_true, y_pred))\n",
    "        metrics['R²'].append(r2_score(y_true, y_pred))\n",
    "    \n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    ax7_twin1 = ax7.twinx()\n",
    "    ax7_twin2 = ax7.twinx()\n",
    "    ax7_twin2.spines['right'].set_position(('outward', 60))\n",
    "    \n",
    "    ax7.bar(x - width, metrics['MSE'], width, label='MSE', color='skyblue', alpha=0.8)\n",
    "    ax7_twin1.bar(x, metrics['MAE'], width, label='MAE', color='lightcoral', alpha=0.8)\n",
    "    ax7_twin2.bar(x + width, metrics['R²'], width, label='R²', color='lightgreen', alpha=0.8)\n",
    "    \n",
    "    ax7.set_xlabel('Model', fontsize=10)\n",
    "    ax7.set_ylabel('MSE', fontsize=10, color='skyblue')\n",
    "    ax7_twin1.set_ylabel('MAE', fontsize=10, color='lightcoral')\n",
    "    ax7_twin2.set_ylabel('R²', fontsize=10, color='lightgreen')\n",
    "    ax7.set_title('Metrics Comparison', fontsize=12, fontweight='bold')\n",
    "    ax7.set_xticks(x)\n",
    "    ax7.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    \n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Detailed comparison plot saved to '{save_path}'\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ===== 使用例 =====\n",
    "if __name__ == \"__main__\":\n",
    "    # サンプルデータ\n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    n_features = 3\n",
    "    \n",
    "    # 真の値\n",
    "    y_test = np.random.randn(n_samples, n_features) * 10 + 50\n",
    "    \n",
    "    # モデルの予測値(シミュレーション)\n",
    "    y_pred_lr = y_test + np.random.randn(n_samples, n_features) * 2\n",
    "    y_pred_qrc = y_test + np.random.randn(n_samples, n_features) * 3\n",
    "    y_pred_rf = y_test + np.random.randn(n_samples, n_features) * 1.5\n",
    "    \n",
    "    # 予測値の辞書\n",
    "    predictions = {\n",
    "        'Linear Regression': y_pred_lr,\n",
    "        'QRC': y_pred_qrc,\n",
    "        'Random Forest': y_pred_rf\n",
    "    }\n",
    "    \n",
    "    # 特徴量名\n",
    "    feature_names = ['Tenor_10_Mat_30', 'Tenor_15_Mat_30', 'Tenor_20_Mat_30']\n",
    "    \n",
    "    # 包括的な比較プロット\n",
    "    plot_comprehensive_comparison(y_test, predictions, feature_names, save_path='comparison.png')\n",
    "    \n",
    "    # 詳細プロット(最初の特徴量)\n",
    "    plot_single_feature_detailed(y_test, predictions, feature_idx=0, \n",
    "                                 feature_name='Tenor_10_Mat_30', \n",
    "                                 save_path='detailed_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac76d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
