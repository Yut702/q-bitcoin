{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fabea-4f98-4a77-bef7-f2c69a2ad4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7963c26-5dd2-4641-ba54-230022a1dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341d5a6-2c56-4d1f-9565-63994f6e1c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70323584-d96a-41a7-8ae0-aa2f19b477fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Qiskit imports (Estimator は Aer 版があれば優先、無ければ Terra 版を使用)\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "try:\n",
    "    from qiskit_aer.primitives import Estimator as QiskitEstimator\n",
    "except Exception:\n",
    "    from qiskit.primitives import Estimator as QiskitEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cd6fcff-f64f-41aa-8374-f630c02c467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Baseline Linear Model\n",
    "class LinearModelBaseline(nn.Module):\n",
    "    def __init__(self, image_size, num_classes=10):\n",
    "        super(LinearModelBaseline, self).__init__()\n",
    "        self.image_size = image_size\n",
    "\n",
    "        # Classical part\n",
    "        self.classifier = nn.Linear(image_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Data is already flattened\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d98b5b-0fb0-4323-b6e1-dee908a7a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearModel with PCA\n",
    "class LinearModelPCA(nn.Module):\n",
    "    def __init__(self, image_size, pca_components, num_classes=10):\n",
    "        super(LinearModelPCA, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.pca_components = pca_components\n",
    "\n",
    "        # Classical part\n",
    "        self.classifier = nn.Linear(image_size + pca_components, num_classes)\n",
    "\n",
    "    def forward(self, x, x_pca):\n",
    "        # Data is already flattened, just concatenate\n",
    "        combined_features = torch.cat((x, x_pca), dim=1)\n",
    "        output = self.classifier(combined_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8f2f3a4-a82f-4fea-b00a-83043d9ece4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Qiskit-based Reservoir layer (non-trainable) --------------------------\n",
    "class QiskitReservoirLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    固定パラメータの量子回路（リザーバ）で PCA 特徴をエンコードし、\n",
    "    観測演算子（既定は Z と ZZ）に対する期待値ベクトルを返す。\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, n_qubits=8, n_layers=2, observables=\"Z+ZZ\", seed=42, shots=None):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.observables = observables\n",
    "\n",
    "        # 回路テンプレート（angle encoding + 軽いエンタングラ）\n",
    "        self.x_params = [Parameter(f\"x{i}\") for i in range(input_size)]\n",
    "        rng = np.random.default_rng(seed)\n",
    "        thetas = rng.uniform(0, 2*np.pi, size=(n_layers, n_qubits))\n",
    "\n",
    "        qc = QuantumCircuit(n_qubits)\n",
    "        # angle encoding: x_i を順番に RY へ（round-robin で割当）\n",
    "        for i in range(input_size):\n",
    "            qc.ry(self.x_params[i], i % n_qubits)\n",
    "        for l in range(n_layers):\n",
    "            for q in range(n_qubits):\n",
    "                qc.rz(float(thetas[l, q]), q)\n",
    "            for q in range(n_qubits - 1):\n",
    "                qc.cx(q, q+1)\n",
    "        self.template = qc\n",
    "\n",
    "        # 観測集合を構成（Z_i と Z_i Z_j）\n",
    "        pauli_list = []\n",
    "        if \"Z\" in observables:\n",
    "            for i in range(n_qubits):\n",
    "                s = [\"I\"] * n_qubits\n",
    "                s[i] = \"Z\"\n",
    "                pauli_list.append((\"\".join(reversed(s)), 1.0))\n",
    "        if \"ZZ\" in observables:\n",
    "            for i in range(n_qubits):\n",
    "                for j in range(i+1, n_qubits):\n",
    "                    s = [\"I\"] * n_qubits\n",
    "                    s[i] = \"Z\"; s[j] = \"Z\"\n",
    "                    pauli_list.append((\"\".join(reversed(s)), 1.0))\n",
    "        self.ops = [SparsePauliOp.from_list([p]) for p in pauli_list]\n",
    "        self.output_size = len(self.ops)\n",
    "\n",
    "        # Estimator（Aer があればサンプリング、無ければ解析モード）\n",
    "        self.estimator = QiskitEstimator() if shots is None else QiskitEstimator(shots=shots)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x_pca: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        x_pca: [B, input_size]\n",
    "        return: [B, output_size] （各観測の期待値）\n",
    "        \"\"\"\n",
    "        device = x_pca.device\n",
    "        x_np = x_pca.detach().cpu().numpy()\n",
    "        features = []\n",
    "        for vec in x_np:\n",
    "            bound = self.template.bind_parameters({p: float(v) for p, v in zip(self.x_params, vec)})\n",
    "            circuits = [bound] * len(self.ops)\n",
    "            res = self.estimator.run(circuits, self.ops).result()\n",
    "            features.append(res.values)\n",
    "        return torch.tensor(np.array(features), dtype=torch.float32, device=device)\n",
    "\n",
    "# definition of QuantumReservoir class - Qiskit reservoir + linear classifier\n",
    "class QuantumReservoir(nn.Module):\n",
    "    def __init__(self, image_size, pca_components, n_qubits=8, n_layers=2, observables=\"Z+ZZ\", num_classes=10):\n",
    "        super(QuantumReservoir, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.pca_components = pca_components\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.observables = observables\n",
    "\n",
    "        # Quantum part (non-trainable reservoir)\n",
    "        self.quantum_layer = QiskitReservoirLayer(\n",
    "            input_size=pca_components,\n",
    "            n_qubits=n_qubits,\n",
    "            n_layers=n_layers,\n",
    "            observables=observables\n",
    "        )\n",
    "\n",
    "        # Classical part\n",
    "        self.classifier = nn.Linear(\n",
    "            image_size + self.quantum_layer.output_size,\n",
    "            num_classes\n",
    "        )\n",
    "\n",
    "        print(f\"\\nQiskit Reservoir Created:\")\n",
    "        print(f\"  Input size (PCA components): {pca_components}\")\n",
    "        print(f\"  Quantum output size: {self.quantum_layer.output_size}  # observables={observables}\")\n",
    "        print(f\"  Total features to classifier: {image_size + self.quantum_layer.output_size}\")\n",
    "\n",
    "    def forward(self, x, x_pca):\n",
    "        q_out = self.quantum_layer(x_pca)\n",
    "        combined = torch.cat((x, q_out), dim=1)\n",
    "        return self.classifier(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83515c1b-7b8f-41eb-888a-0c27558b7a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded (torchvision): 6000 training samples, 600 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST を torchvision から取得（Merlin 依存を排除）\n",
    "transform = transforms.ToTensor()\n",
    "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# 速度・再現性のため元コードに合わせてサブセット（6000/600）を使用\n",
    "N_TRAIN, N_TEST = 6000, 600\n",
    "train_images = train_ds.data[:N_TRAIN].view(N_TRAIN, -1).float() / 255.0\n",
    "test_images  = test_ds.data[:N_TEST].view(N_TEST, -1).float() / 255.0\n",
    "train_labels = train_ds.targets[:N_TRAIN]\n",
    "test_labels  = test_ds.targets[:N_TEST]\n",
    "\n",
    "X_train = train_images.clone().detach()\n",
    "X_test  = test_images.clone().detach()\n",
    "y_train = train_labels.clone().detach().long()\n",
    "y_test  = test_labels.clone().detach().long()\n",
    "\n",
    "print(f\"Dataset loaded (torchvision): {len(X_train)} training samples, {len(X_test)} test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0c40810-dcae-439b-be59-b7269954b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 8\n",
    "# Qiskit reservoir parameters\n",
    "n_qubits = 8\n",
    "n_layers = 2\n",
    "observables = \"Z+ZZ\"  # 必要に応じて観測集合を拡張可（メモ参照）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57234ce9-1c2d-4ae1-bb98-af93891f4c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5324,  1.3737, -0.1363,  ..., -1.1627,  0.7187,  0.1862],\n",
      "        [ 4.2491,  1.2599, -1.9936,  ..., -1.1285, -0.2313, -0.5979],\n",
      "        [-0.2846, -1.7457,  1.1546,  ...,  0.3840, -3.6403,  0.9226],\n",
      "        ...,\n",
      "        [ 0.0393,  2.6523, -2.9366,  ...,  0.3909,  0.4807, -1.8218],\n",
      "        [ 1.1493,  0.2049, -1.3050,  ..., -3.4043,  0.2989,  1.2935],\n",
      "        [ 0.8179, -3.1770, -1.8832,  ...,  0.4889,  1.4898, -0.6843]])\n"
     ]
    }
   ],
   "source": [
    "# train PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Note: Data is already flattened\n",
    "X_train_flat = X_train\n",
    "X_test_flat = X_test\n",
    "\n",
    "pca.fit(X_train_flat)\n",
    "X_train_pca = torch.FloatTensor(pca.transform(X_train_flat))\n",
    "X_test_pca = torch.FloatTensor(pca.transform(X_test_flat))\n",
    "print(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a09c37-19ce-47cc-9f8e-866d7d41d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define corresponding linear model for comparison\n",
    "linear_model = LinearModelBaseline(X_train_flat.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da3d07ef-924c-4df8-88cb-fb85450ef826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model using pca featues\n",
    "pca_model = LinearModelPCA(X_train_flat.shape[1], n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faa85bd5-0003-4df7-ad22-ee64e4517057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qiskit Reservoir Created:\n",
      "  Input size (PCA components): 8\n",
      "  Quantum output size: 36  # observables=Z+ZZ\n",
      "  Total features to classifier: 820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/m92t66fj7dv5gcb95qrn8hb40000gn/T/ipykernel_47193/885459750.py:76: DeprecationWarning: Estimator has been deprecated as of Aer 0.15, please use EstimatorV2 instead.\n",
      "  self.quantum_layer = QiskitReservoirLayer(\n",
      "/var/folders/cv/m92t66fj7dv5gcb95qrn8hb40000gn/T/ipykernel_47193/885459750.py:76: DeprecationWarning: Option approximation=False is deprecated as of qiskit-aer 0.13. It will be removed no earlier than 3 months after the release date. Instead, use BackendEstimator from qiskit.primitives.\n",
      "  self.quantum_layer = QiskitReservoirLayer(\n"
     ]
    }
   ],
   "source": [
    "# define hybrid model (Qiskit reservoir)\n",
    "hybrid_model = QuantumReservoir(\n",
    "    image_size=X_train_flat.shape[1],\n",
    "    pca_components=n_components,\n",
    "    n_qubits=n_qubits,\n",
    "    n_layers=n_layers,\n",
    "    observables=observables\n",
    ")\n",
    "# フォトニック回路可視化は削除（Qiskit 版は Estimator のみ使用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4da38d9-d3c1-4d00-a21d-f389eee7a08d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QuantumCircuit' object has no attribute 'bind_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m pca_model.train()\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, pca_features, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Hybrid model - Forward and Backward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     outputs = \u001b[43mhybrid_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpca_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     loss = criterion(outputs, labels)\n\u001b[32m     35\u001b[39m     optimizer_hybrid.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mQuantumReservoir.forward\u001b[39m\u001b[34m(self, x, x_pca)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, x_pca):\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     q_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquantum_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_pca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     combined = torch.cat((x, q_out), dim=\u001b[32m1\u001b[39m)\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classifier(combined)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit-venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mQiskitReservoirLayer.forward\u001b[39m\u001b[34m(self, x_pca)\u001b[39m\n\u001b[32m     57\u001b[39m features = []\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m vec \u001b[38;5;129;01min\u001b[39;00m x_np:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     bound = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_parameters\u001b[49m({p: \u001b[38;5;28mfloat\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m p, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.x_params, vec)})\n\u001b[32m     60\u001b[39m     circuits = [bound] * \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.ops)\n\u001b[32m     61\u001b[39m     res = \u001b[38;5;28mself\u001b[39m.estimator.run(circuits, \u001b[38;5;28mself\u001b[39m.ops).result()\n",
      "\u001b[31mAttributeError\u001b[39m: 'QuantumCircuit' object has no attribute 'bind_parameters'"
     ]
    }
   ],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_linear = torch.optim.Adam(linear_model.parameters(), lr=0.001)\n",
    "optimizer_pca = torch.optim.Adam(pca_model.parameters(), lr=0.001)\n",
    "optimizer_hybrid = torch.optim.Adam(hybrid_model.parameters(), lr=0.001)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "batch_size = 128\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, X_train_pca, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "\n",
    "history = {\n",
    "      'hybrid': {'loss': [], 'accuracy': []},\n",
    "      'pca': {'loss': [], 'accuracy': []},\n",
    "      'linear': {'loss': [], 'accuracy': []},\n",
    "      'epochs': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss_hybrid = 0.0\n",
    "    running_loss_linear = 0.0\n",
    "    running_loss_pca = 0.0\n",
    "\n",
    "    hybrid_model.train()\n",
    "    linear_model.train()\n",
    "    pca_model.train()\n",
    "\n",
    "    for i, (images, pca_features, labels) in enumerate(train_loader):\n",
    "        # Hybrid model - Forward and Backward pass\n",
    "        outputs = hybrid_model(images, pca_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer_hybrid.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_hybrid.step()\n",
    "        running_loss_hybrid += loss.item()\n",
    "\n",
    "        # Comparative linear model - Forward and Backward pass\n",
    "        outputs = linear_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer_linear.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_linear.step()\n",
    "        running_loss_linear += loss.item()\n",
    "\n",
    "        # Comparative pca model - Forward and Backward pass\n",
    "        outputs = pca_model(images, pca_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer_pca.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_pca.step()\n",
    "        running_loss_pca += loss.item()\n",
    "\n",
    "    avg_loss_hybrid = running_loss_hybrid/len(train_loader)\n",
    "    avg_loss_linear = running_loss_linear/len(train_loader)\n",
    "    avg_loss_pca = running_loss_pca/len(train_loader)\n",
    "\n",
    "    history['hybrid']['loss'].append(avg_loss_hybrid)\n",
    "    history['linear']['loss'].append(avg_loss_linear)\n",
    "    history['pca']['loss'].append(avg_loss_pca)\n",
    "\n",
    "    history['epochs'].append(epoch + 1)\n",
    "\n",
    "    hybrid_model.eval()\n",
    "    linear_model.eval()\n",
    "    pca_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = hybrid_model(X_test, X_test_pca)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        hybrid_accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "\n",
    "        outputs = linear_model(X_test)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        linear_accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "\n",
    "        outputs = pca_model(X_test, X_test_pca)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        pca_accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "\n",
    "    history['hybrid']['accuracy'].append(hybrid_accuracy)\n",
    "    history['linear']['accuracy'].append(linear_accuracy)\n",
    "    history['pca']['accuracy'].append(pca_accuracy)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], LOSS -- Hybrid: {avg_loss_hybrid:.4f}, Linear: {avg_loss_linear:.4f}, PCA: {avg_loss_pca:.4f}'+\n",
    "          f', ACCURACY -- Hybrid: {hybrid_accuracy:.4f}, Linear: {linear_accuracy:.4f}, PCA: {pca_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388004e-83ff-4e6a-800e-1cab34bda10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_training_comparison(history):\n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "    # Define colors and styles for consistency\n",
    "    model_styles = {\n",
    "      'hybrid': {'color': 'blue', 'linestyle': '-', 'marker': 'o'},\n",
    "      'pca': {'color': 'green', 'linestyle': '-', 'marker': 's'},\n",
    "      'linear': {'color': 'red', 'linestyle': '-', 'marker': '^'}\n",
    "    }\n",
    "\n",
    "    # Plot loss curves\n",
    "    for model_name, style in model_styles.items():\n",
    "      if model_name in history:\n",
    "          ax1.plot(\n",
    "              history['epochs'],\n",
    "              history[model_name]['loss'],\n",
    "              color=style['color'],\n",
    "              linestyle=style['linestyle'],\n",
    "              marker=style['marker'],\n",
    "              markevery=max(1, len(history['epochs'])//10),  # Show markers at 10 points\n",
    "              label=f'{model_name.capitalize()} Model'\n",
    "          )\n",
    "\n",
    "    ax1.set_title('Training Loss Comparison', fontsize=14)\n",
    "    ax1.set_xlabel('Epochs', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.legend(fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot accuracy curves\n",
    "    for model_name, style in model_styles.items():\n",
    "      if model_name in history:\n",
    "          ax2.plot(\n",
    "              history['epochs'],\n",
    "              history[model_name]['accuracy'],\n",
    "              color=style['color'],\n",
    "              linestyle=style['linestyle'],\n",
    "              marker=style['marker'],\n",
    "              markevery=max(1, len(history['epochs'])//10),  # Show markers at 10 points\n",
    "              label=f'{model_name.capitalize()} Model'\n",
    "          )\n",
    "\n",
    "    ax2.set_title('Training Accuracy Comparison', fontsize=14)\n",
    "    ax2.set_xlabel('Epochs', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax2.legend(fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to generate the plot\n",
    "plot_training_comparison(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
